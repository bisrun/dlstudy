{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 배치 크기 × 채널 × 높이(height) × 너비(widht)의 크기의 텐서를 선언\n",
    "inputs = torch.Tensor(1, 1, 28, 28)\n",
    "print('텐서의 크기 : {}'.format(inputs.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "# 1번 레이어 : 합성곱층(Convolutional layer)\n",
    "#합성곱(in_channel = 1, out_channel = 32, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
    "conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "print(conv1)\n",
    "\n",
    "# 2번 레이어 : 합성곱층(Convolutional layer)\n",
    "#합성곱(in_channel = 32, out_channel = 64, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
    "conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "print(conv2)\n",
    "\n",
    "#맥스풀링(kernel_size=2, stride=2))\n",
    "pool = nn.MaxPool2d(2)\n",
    "print(pool)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 28, 28])\n",
      "torch.Size([1, 32, 14, 14])\n",
      "torch.Size([1, 64, 14, 14])\n",
      "torch.Size([1, 64, 7, 7])\n",
      "1\n",
      "64\n",
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "out = conv1(inputs)\n",
    "print(out.shape)\n",
    "out = pool(out)\n",
    "print(out.shape)\n",
    "out = conv2(out)\n",
    "print(out.shape)\n",
    "out = pool(out)\n",
    "print(out.shape)\n",
    "#현재 out의 크기는 1 × 64 × 7 × 7입니다.\n",
    "# out의 첫번째 차원이 몇인지 출력해보겠습니다.\n",
    "print(out.size(0))\n",
    "#out의 첫번째 차원은 1입니다.\n",
    "#두번째 차원이 몇인지 출력해보겠습니다.\n",
    "print(out.size(1))\n",
    "print(out.size(2))\n",
    "print(out.size(3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3136])\n"
     ]
    }
   ],
   "source": [
    "#.view() 를 사용하여 텐서를 펼치는 작업\n",
    "out = out.view(out.size(0), -1)\n",
    "print(out.shape)\n",
    "#배치 차원을 제외하고 모두 하나의 차원으로 통합된 것을 볼 수 있습니다.\n",
    "# 이제 이에 대해서 전결합층(Fully-Connteced layer)를 통과시켜보겠습니다.\n",
    "# 출력층으로 10개의 뉴런을 배치하여 10개 차원의 텐서로 변환합니다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3136\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape[1])\n",
    "fc = nn.Linear(out.shape[1], 10) # # input_dim = 3,136, output_dim = 10\n",
    "out = fc(out)\n",
    "print(out.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 3. CNN으로 MNIST 분류하기\n",
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epoch = 15\n",
    "batch_size = 100\n",
    "\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',#다운로드 경로\n",
    "                          train=True,\n",
    "                          transform = transforms.ToTensor(),#텐서로 변환\n",
    "                          download=True )\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',#다운로드 경로\n",
    "                          train=False,\n",
    "                          transform = transforms.ToTensor(),#텐서로 변환\n",
    "                          download=True )\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset = mnist_train,\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle = True,\n",
    "                                          drop_last = True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #layer 1\n",
    "        #ImgIn shape = (?, 28,28, 1)\n",
    "        #  conv --> (?, 28,28,32)\n",
    "        #  pool --> (?, 14,14,32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        #layer 2\n",
    "        #ImgIn shape = (?, 14, 14, 32)\n",
    "        #  conv --> (?, 14,14,64)\n",
    "        #  pool --> (?, 7,7,64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        #fully connected layer\n",
    "        self.fc = torch.nn.Linear(7*7*64, 10, bias=True)\n",
    "\n",
    "        #\n",
    "        torch.nn.init.xavier_uniform(self.fc.weight)\n",
    "\n",
    "    def forward(self, x ):\n",
    "        out =self.layer1(x)\n",
    "        out =self.layer2(out)\n",
    "        out = out.view(out.size(0), -1) #fully connected layer를 위해 flatten\n",
    "        out = self.fc(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp/ipykernel_20732/3232897716.py:27: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total batch count = 600\n",
      "training epoch count 15\n",
      "epoch:    1 cost=0.212764308\n",
      "epoch:    2 cost=0.0589677915\n",
      "epoch:    3 cost=0.0425912328\n",
      "epoch:    4 cost=0.0342711508\n",
      "epoch:    5 cost=0.0284705404\n",
      "epoch:    6 cost=0.0231754892\n",
      "epoch:    7 cost=0.0196241047\n",
      "epoch:    8 cost=0.0164618138\n",
      "epoch:    9 cost=0.0142560797\n",
      "epoch:   10 cost=0.0116690882\n",
      "epoch:   11 cost=0.0100624152\n",
      "epoch:   12 cost=0.0094806226\n",
      "epoch:   13 cost=0.0081340177\n",
      "epoch:   14 cost=0.00661981525\n",
      "epoch:   15 cost=0.00724106608\n"
     ]
    }
   ],
   "source": [
    "#define model\n",
    "model = CNN().to(device)\n",
    "\n",
    "criterian = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "total_batch = len(data_loader)\n",
    "print('total batch count = {}'.format(total_batch))\n",
    "print(\"training epoch count\", training_epoch)\n",
    "\n",
    "for epoch in range(training_epoch):\n",
    "    avg_cost = 0\n",
    "    for X, Y in data_loader: #미니배치 단위로 꺼내온다.  X는 미니배치, Y는 레이블\n",
    "        #image is already size of 28*28 , no reshape\n",
    "        #label is not one-hot encoded\n",
    "        X=X.to(device)\n",
    "        Y=Y.to(device)\n",
    "        #print(X.shape, Y.shape)\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterian(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('epoch: {:>4} cost={:>.9}'.format(epoch + 1, avg_cost))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9873999953269958\n"
     ]
    }
   ],
   "source": [
    "#테스트, 학습을 진행하지 않으므로 torch.no_grad\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1,28,28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, dim=1 ) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8b08f4db",
   "language": "python",
   "display_name": "PyCharm (torch04)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}