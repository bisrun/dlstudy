{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor(1.)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "\n",
    "z = torch.FloatTensor([1,2,3])\n",
    "\n",
    "hypothesis = F.softmax(z, dim=0)\n",
    "print(hypothesis)\n",
    "\n",
    "hypothesis.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2025, 0.2176, 0.2324, 0.1142, 0.2333],\n",
      "        [0.1503, 0.1465, 0.2203, 0.1962, 0.2866],\n",
      "        [0.1473, 0.1262, 0.2831, 0.1827, 0.2607]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z = torch.rand(3,5, requires_grad=True)\n",
    "\n",
    "hypothesis = F.softmax(z, dim=1) # 행에 속한 각 열의 합이 1이 되도록\n",
    "print(hypothesis)\n",
    "print(hypothesis.sum(dim=1))# 행에 속한 각 열의 합을 구함, 행(dim=0)의 개수가 유지됨\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "#이제 각 샘플에 대해서 임의의 레이블을 만듭니다\n",
    "y = torch.randint(5, (3,)).long()\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([0, 3, 2])\n",
      "tensor([[0],\n",
      "        [3],\n",
      "        [2]])\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 모든 원소가 0의 값을 가진 3 × 5 텐서 생성\n",
    "y_one_hot = torch.zeros_like(hypothesis)\n",
    "print(y_one_hot)\n",
    "\n",
    "#Tensor.scatter_(dim, index, src, reduce=None) → Tensor\n",
    "print(y)\n",
    "print(y.unsqueeze(1))\n",
    "y_one_hot.scatter_(1, y.unsqueeze(1), 1) # 맨위의 _ 는 덮어쓰기\n",
    "print(y_one_hot)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5971, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.6285, 0.0000],\n",
      "        [0.0000, 0.0000, 1.2618, 0.0000, 0.0000]], grad_fn=<MulBackward0>)\n",
      "tensor([1.5971, 1.6285, 1.2618], grad_fn=<SumBackward1>)\n",
      "tensor(1.4958, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print((y_one_hot * -torch.log(hypothesis)))\n",
    "print((y_one_hot * -torch.log(hypothesis)).sum(dim=1))\n",
    "cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()\n",
    "print(cost)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5971, -1.5252, -1.4591, -2.1701, -1.4553],\n",
      "        [-1.8948, -1.9205, -1.5129, -1.6285, -1.2496],\n",
      "        [-1.9153, -2.0702, -1.2618, -1.6998, -1.3445]], grad_fn=<LogBackward>)\n",
      "tensor([[-1.5971, -1.5252, -1.4591, -2.1701, -1.4553],\n",
      "        [-1.8948, -1.9205, -1.5129, -1.6285, -1.2496],\n",
      "        [-1.9153, -2.0702, -1.2618, -1.6998, -1.3445]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0.]])\n",
      "tensor(1.4958, grad_fn=<MeanBackward0>)\n",
      "tensor(1.4958, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#파이토치로 소프트맥스 비용함수 구현하기\n",
    "#low level\n",
    "ls1 = torch.log(F.softmax(z,dim=1))\n",
    "print(ls1)\n",
    "ls2 = F.log_softmax(z,dim=1)\n",
    "print(ls2)\n",
    "\n",
    "print(y_one_hot)\n",
    "c1= (y_one_hot * -torch.log(F.softmax(z,dim=1))).sum(dim=1).mean()\n",
    "c2 = (y_one_hot * -F.log_softmax(z,dim=1)).sum(dim=1).mean()\n",
    "print(c1)\n",
    "print(c2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 3, 2])\n",
      "tensor(1.4958, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#여기서 nll이란 Negative Log Likelihood의 약자입니다. 위에서 nll_loss는 F.log_softmax()를 수행한 후에 남은 수식들을 수행\n",
    "print(y)\n",
    "c3= F.nll_loss(F.log_softmax(z,dim=1),y)\n",
    "print(c3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.4958, grad_fn=<NllLossBackward>)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(z, y)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8b08f4db",
   "language": "python",
   "display_name": "PyCharm (torch04)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}